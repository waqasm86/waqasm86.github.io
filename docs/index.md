# Mohammad Waqas (waqasm86)

Welcome to my personal engineering hub.

Here I publish **CUDA + C++ + LLM inference** work, benchmarks, and architecture notes.

## Featured
- CUDA networking experiments for llama.cpp
- Multi-rank scheduling / throughput tests
- Storage pipeline experiments for LLM workloads
