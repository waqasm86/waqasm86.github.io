# CUDA Projects

This section contains documentation, design notes, build steps, and results for my CUDA repositories.

### [cuda-nvidia-systems-engg](cuda-nvidia-systems-engg.md)
Production-grade distributed LLM inference system combining TCP networking, MPI scheduling, content-addressed storage, and empirical performance research.

### [local-llama-cuda](local-llama-cuda.md)
Custom CUDA implementation with MPI-based distributed inference

### [cuda-tcp-llama.cpp](cuda-tcp-llama.md)
High-performance TCP inference gateway with epoll async I/O

### [cuda-openmpi](cuda-openmpi.md)
CUDA-aware OpenMPI integration and testing

### [cuda-mpi-llama-scheduler](cuda-mpi-llama-scheduler.md)
Distributed scheduler with work-stealing and percentile analysis

### [cuda-llm-storage-pipeline](cuda-llm-storage-pipeline.md)
Content-addressed model distribution with SHA256 verification
